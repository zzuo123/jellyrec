{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bcd2362",
   "metadata": {},
   "source": [
    "# Trying things out\n",
    "## Step 1: Download ml-small and unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "894fb908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset already exists. No download needed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "\n",
    "# URL of the dataset\n",
    "url = \"https://files.grouplens.org/datasets/movielens/ml-latest-small.zip\"\n",
    "# Path to save the downloaded zip file\n",
    "zip_path = \"ml-latest-small.zip\"\n",
    "# Directory to extract the contents\n",
    "extract_dir = \"ml-latest-small\"\n",
    "\n",
    "# Check if the directory already exists\n",
    "if not os.path.exists(extract_dir):\n",
    "    # Download the zip file\n",
    "    print(\"Downloading the dataset...\")\n",
    "    response = requests.get(url)\n",
    "    with open(zip_path, \"wb\") as file:\n",
    "        file.write(response.content)\n",
    "    \n",
    "    # Unzip the file\n",
    "    print(\"Unzipping the dataset...\")\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "    \n",
    "    # Clean up the zip file\n",
    "    os.remove(zip_path)\n",
    "    print(\"Download and extraction complete.\")\n",
    "else:\n",
    "    print(\"Dataset already exists. No download needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9dccfd0",
   "metadata": {},
   "source": [
    "## Step 2: load rating data into pandas and clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbf7b5c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating\n",
       "0       1        1     4.0\n",
       "1       1        3     4.0\n",
       "2       1        6     4.0\n",
       "3       1       47     5.0\n",
       "4       1       50     5.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./ml-latest-small/ml-latest-small/ratings.csv\")\n",
    "df.drop(['timestamp'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7524a515",
   "metadata": {},
   "source": [
    "## Step 3: Load data into surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2540bdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Dataset\n",
    "from surprise import Reader\n",
    "\n",
    "reader = Reader(rating_scale=(1, 5))\n",
    "data = Dataset.load_from_df(df[[\"userId\", \"movieId\", \"rating\"]], reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d667de",
   "metadata": {},
   "source": [
    "## Step 4: Simple KNN recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8de57281",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import KNNWithMeans\n",
    "\n",
    "# To use user-based cosine similarity\n",
    "sim_options = {\n",
    "    \"name\": \"cosine\",\n",
    "    \"user_based\": True,  # Compute  similarities between users\n",
    "}\n",
    "algo = KNNWithMeans(sim_options=sim_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87199767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.knns.KNNWithMeans at 0x7fb661ac5150>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingSet = data.build_full_trainset()\n",
    "algo.fit(trainingSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bbcfb53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.2047694753577107, 179)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = 5\n",
    "movie = 1\n",
    "while score >= 1.5:\n",
    "    prediction = algo.predict(100, movie)\n",
    "    score = prediction.est\n",
    "    movie += 1\n",
    "score, movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c86fba57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4.993689831844592, 2296)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = 0\n",
    "movie = 1\n",
    "while score < 4.99 or score == 5:\n",
    "    prediction = algo.predict(100, movie)\n",
    "    score = prediction.est\n",
    "    movie += 1\n",
    "score, movie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f1561d",
   "metadata": {},
   "source": [
    "## Algorithm Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38b71228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting:  [<surprise.prediction_algorithms.matrix_factorization.SVD object at 0x7fb612e87850>, <surprise.prediction_algorithms.matrix_factorization.SVDpp object at 0x7fb664448590>, <surprise.prediction_algorithms.slope_one.SlopeOne object at 0x7fb664437b10>, <surprise.prediction_algorithms.matrix_factorization.NMF object at 0x7fb664449250>, <surprise.prediction_algorithms.random_pred.NormalPredictor object at 0x7fb661c04250>, <surprise.prediction_algorithms.knns.KNNBaseline object at 0x7fb660875610>, <surprise.prediction_algorithms.knns.KNNBasic object at 0x7fb6940e5510>, <surprise.prediction_algorithms.knns.KNNWithMeans object at 0x7fb65e52dc50>, <surprise.prediction_algorithms.knns.KNNWithZScore object at 0x7fb65e52e010>, <surprise.prediction_algorithms.co_clustering.CoClustering object at 0x7fb65e52f110>] \n",
      "\n",
      "\n",
      "\n",
      "Starting:  <surprise.prediction_algorithms.matrix_factorization.SVD object at 0x7fb612e87850>\n",
      "Done:  <surprise.prediction_algorithms.matrix_factorization.SVD object at 0x7fb612e87850> \n",
      "\n",
      "\n",
      "Starting:  <surprise.prediction_algorithms.matrix_factorization.SVDpp object at 0x7fb664448590>\n",
      "Done:  <surprise.prediction_algorithms.matrix_factorization.SVDpp object at 0x7fb664448590> \n",
      "\n",
      "\n",
      "Starting:  <surprise.prediction_algorithms.slope_one.SlopeOne object at 0x7fb664437b10>\n",
      "Done:  <surprise.prediction_algorithms.slope_one.SlopeOne object at 0x7fb664437b10> \n",
      "\n",
      "\n",
      "Starting:  <surprise.prediction_algorithms.matrix_factorization.NMF object at 0x7fb664449250>\n",
      "Done:  <surprise.prediction_algorithms.matrix_factorization.NMF object at 0x7fb664449250> \n",
      "\n",
      "\n",
      "Starting:  <surprise.prediction_algorithms.random_pred.NormalPredictor object at 0x7fb661c04250>\n",
      "Done:  <surprise.prediction_algorithms.random_pred.NormalPredictor object at 0x7fb661c04250> \n",
      "\n",
      "\n",
      "Starting:  <surprise.prediction_algorithms.knns.KNNBaseline object at 0x7fb660875610>\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done:  <surprise.prediction_algorithms.knns.KNNBaseline object at 0x7fb660875610> \n",
      "\n",
      "\n",
      "Starting:  <surprise.prediction_algorithms.knns.KNNBasic object at 0x7fb6940e5510>\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done:  <surprise.prediction_algorithms.knns.KNNBasic object at 0x7fb6940e5510> \n",
      "\n",
      "\n",
      "Starting:  <surprise.prediction_algorithms.knns.KNNWithMeans object at 0x7fb65e52dc50>\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done:  <surprise.prediction_algorithms.knns.KNNWithMeans object at 0x7fb65e52dc50> \n",
      "\n",
      "\n",
      "Starting:  <surprise.prediction_algorithms.knns.KNNWithZScore object at 0x7fb65e52e010>\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Done:  <surprise.prediction_algorithms.knns.KNNWithZScore object at 0x7fb65e52e010> \n",
      "\n",
      "\n",
      "Starting:  <surprise.prediction_algorithms.co_clustering.CoClustering object at 0x7fb65e52f110>\n",
      "Done:  <surprise.prediction_algorithms.co_clustering.CoClustering object at 0x7fb65e52f110> \n",
      "\n",
      "\n",
      "\n",
      "\tDONE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from surprise import SVD, SVDpp, SlopeOne, NMF, NormalPredictor, KNNBaseline, KNNBasic, KNNWithMeans, KNNWithZScore, CoClustering\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise.accuracy import rmse\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "benchmark = []\n",
    "# Iterate over all algorithms\n",
    "\n",
    "algorithms = [SVD(), SVDpp(), SlopeOne(), NMF(), NormalPredictor(), KNNBaseline(), KNNBasic(), KNNWithMeans(), KNNWithZScore(), CoClustering()]\n",
    "\n",
    "print (\"Attempting: \", str(algorithms), '\\n\\n\\n')\n",
    "\n",
    "for algorithm in algorithms:\n",
    "    print(\"Starting: \" ,str(algorithm))\n",
    "    # Perform cross validation\n",
    "    results = cross_validate(algorithm, data, measures=['RMSE','MAE'], cv=3, verbose=False)\n",
    "    \n",
    "    # Get results & append algorithm name\n",
    "    tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "    tmp = tmp._append(pd.Series([str(algorithm).split(' ')[0].split('.')[-1]], index=['Algorithm']))\n",
    "    benchmark.append(tmp)\n",
    "    print(\"Done: \" ,str(algorithm), \"\\n\\n\")\n",
    "\n",
    "print ('\\n\\tDONE\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7deb67a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>test_mae</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVDpp</th>\n",
       "      <td>0.868893</td>\n",
       "      <td>0.666767</td>\n",
       "      <td>50.728872</td>\n",
       "      <td>11.452713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVD</th>\n",
       "      <td>0.879154</td>\n",
       "      <td>0.675766</td>\n",
       "      <td>0.910505</td>\n",
       "      <td>0.191343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNBaseline</th>\n",
       "      <td>0.880937</td>\n",
       "      <td>0.673486</td>\n",
       "      <td>0.212441</td>\n",
       "      <td>1.617064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithZScore</th>\n",
       "      <td>0.903403</td>\n",
       "      <td>0.685033</td>\n",
       "      <td>0.129243</td>\n",
       "      <td>1.516339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNWithMeans</th>\n",
       "      <td>0.905492</td>\n",
       "      <td>0.692235</td>\n",
       "      <td>0.084611</td>\n",
       "      <td>1.317035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SlopeOne</th>\n",
       "      <td>0.907989</td>\n",
       "      <td>0.695756</td>\n",
       "      <td>3.923813</td>\n",
       "      <td>6.456029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMF</th>\n",
       "      <td>0.934452</td>\n",
       "      <td>0.716532</td>\n",
       "      <td>1.828848</td>\n",
       "      <td>0.202090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CoClustering</th>\n",
       "      <td>0.950586</td>\n",
       "      <td>0.736584</td>\n",
       "      <td>1.822705</td>\n",
       "      <td>0.226071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNNBasic</th>\n",
       "      <td>0.956058</td>\n",
       "      <td>0.734074</td>\n",
       "      <td>0.064636</td>\n",
       "      <td>1.282334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NormalPredictor</th>\n",
       "      <td>1.422280</td>\n",
       "      <td>1.138334</td>\n",
       "      <td>0.077247</td>\n",
       "      <td>0.134600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 test_rmse  test_mae   fit_time  test_time\n",
       "Algorithm                                                 \n",
       "SVDpp             0.868893  0.666767  50.728872  11.452713\n",
       "SVD               0.879154  0.675766   0.910505   0.191343\n",
       "KNNBaseline       0.880937  0.673486   0.212441   1.617064\n",
       "KNNWithZScore     0.903403  0.685033   0.129243   1.516339\n",
       "KNNWithMeans      0.905492  0.692235   0.084611   1.317035\n",
       "SlopeOne          0.907989  0.695756   3.923813   6.456029\n",
       "NMF               0.934452  0.716532   1.828848   0.202090\n",
       "CoClustering      0.950586  0.736584   1.822705   0.226071\n",
       "KNNBasic          0.956058  0.734074   0.064636   1.282334\n",
       "NormalPredictor   1.422280  1.138334   0.077247   0.134600"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surprise_results = pd.DataFrame(benchmark).set_index('Algorithm').sort_values('test_rmse')\n",
    "surprise_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71398e1",
   "metadata": {},
   "source": [
    "### Conclusion:\n",
    "Based on the above observations, it seems like the SVD algorithm provides similar performance (both rmse and mae) compared to SVD++ while using significantly less time to fit and test. Therefore we should probably use SVD for our recommendation system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abd6975",
   "metadata": {},
   "source": [
    "### Credit:\n",
    "This experiment roughly follows [this google colab](https://colab.research.google.com/github/singhsidhukuldeep/Recommendation-System/blob/master/Building_Recommender_System_with_Surprise.ipynb#scrollTo=_zqHKyGm38B4) but uses my own dataset and I made some minor changes with the parameter used as well as modifying tmp.append to tmp._append to supress panda error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e02f1db6",
   "metadata": {},
   "source": [
    "## NMF & SVD for Rec Sys: how does it work?\n",
    "They actually work pretty similarlly. Initially we have a user-rating matrix, with each row being a user and each column being a movie for example, each entry would be a rating.\n",
    "\n",
    "Now it is obvious that most of the cells in the matrix would be left blank since each person would only rate a small percentage of all the movies that are out there. So what both of these method would do is provide a way to estimate what the ratings in these cells would be if they were filled in.\n",
    "\n",
    "Both methods works by decomposing the user-rating matrix into smaller dimention matrices, that when multiplied together, would result in a matrix that is the same dimention as the original user-rating matrix. And more importantly, the value in cells of the multiplied smaller maitrces corresoponding to the filled out cells in the original matrix would be similar to the value of their corresponding cell in the original matrix. That's how we know these methods \"might\" make an accurate estimation of the missing ratings (non-filled cells in the original matrix).\n",
    "\n",
    "The intuition is that by factoring the original matrix, we extract the latent-factors in it, which encodes the information about the user's rating, such as how much a user value action movies vs others, or how much action is in a movie vs other genre. Then when multiplying the smaller matrices back, it generates a rating based on those information. \n",
    "\n",
    "Matrix Factorization is generally considered faster but less accurate compared to SVD, but somehow in this case SVD is faster (I am suspecting some weird optimization issue), so we should probably stick with SVD."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bc11a6",
   "metadata": {},
   "source": [
    "If this doesn't work, use item based and KNN: https://www.analyticsvidhya.com/blog/2020/11/create-your-own-movie-movie-recommendation-system/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
